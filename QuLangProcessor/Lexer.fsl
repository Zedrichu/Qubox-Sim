// The generated lexer module will start with this code
{
open FSharp.Text.Lexing
open System

// Open the module that defines the Tokens
open Parser

// Set the language to English such that 4.0 is parsed as 4 and not 40.
System.Globalization.CultureInfo.CurrentCulture <- new System.Globalization.CultureInfo("en-US")
}

// Define macros for some regular expressions used later
let digit       = ['0'-'9'] 
let num         = digit+
let float       = (digit* '.' digit+ )
//let float       = digit+ ( '.' digit+ | 'E' ('+'|'-')? digit+ )+
let whitespace  = [' ' '\t']
let newline     = "\n\r" | '\n' | '\r'
let char        = ['a'-'z' 'A'-'Z']
let variable    =  char ( char | digit | _ )*
let bool        = "true"|"false"
//digit can also be \d+ 
//whitespace can also be [\u00A0 \n \r \t]

// Define rules for recognising and building tokens
// NOTE: rules are applied in order top-down.
rule tokenize = parse

// deal with tokens that need to be ignored (skip them)
| whitespace    { tokenize lexbuf }
| newline       { lexbuf.EndPos <- lexbuf.EndPos.NextLine; tokenize lexbuf; }
// deal with tokens that need to be built
| float         { FLOAT(Double.Parse(LexBuffer<_>.LexemeString lexbuf ))}
| num           { NUM(Int32.Parse(LexBuffer<_>.LexemeString lexbuf )) }
| bool          { BOOL(Boolean.Parse(LexBuffer<_>.LexemeString lexbuf )) }

// Arithmetic expressions to TOKENs
| '*'               { TIMES }
| '/'               { DIV }
| '+'               { PLUS }
| '-'               { MINUS }
| '^'               { POW }
| '%'               { MOD }    
| "Pi"              { MATHPI }
| '('               { LPAR }
| ')'               { RPAR }
| eof               { EOF }
| '['               { LBRAK }
| ']'               { RBRAK }

// Result TOKENs
| "Click"        { CLICK }
| "NoClick"      { NOCLICK }

// Boolean expression to TOKENs
| "and"         { AND }
| "or"          { OR }
| "xor"         { XOR }
| "&&"          { SAND }
| "||"          { SOR }
| "not"         { NEG }
| '~'           { BVAR }      
| "=="          { EQUAL }
| "|>"          { ISQ }
| "!="          { NOTEQ }
| '>'           { GREATER }
| ">="          { GREATEREQ }
| '<'           { LESS }
| "<="          { LESSEQ }

// Operator expressions to TOKENs
| "Qalloc"whitespace    { QUANTREG }
| "Calloc"whitespace    { CLASSREG }
| "=|"                  { BASSIGN }
| ":="                  { ASSIGN }
| ';'                   { DEL }
| ','                   { SEP }
| "Measure"whitespace   { MEASURE }
| "->"                  { MESHOST }
| "Reset"whitespace     { RESET }
| "If"                  { CONDITIONAL }
| "Barrier"whitespace   { BARRIER }
| "PhaseDisk"           { PHASEDISK }

// Quantum gate expression to TOKENs 
| "H"whitespace         { HADAMARD }
| "ID"whitespace        { IDENTITY }
| "X"whitespace         { PAULIX }
| "Y"whitespace         { PAULIY }
| "Z"whitespace         { PAULIZ }
| "TDG"whitespace       { TDAGGER }
| "T"whitespace         { TGATE }
| "S"whitespace         { SGATE }
| "SDG"whitespace       { SDAGGER }
| "SX"whitespace        { SQRTNOT }
| "SXDG"whitespace      { SQRTXDG }
| "P"                   { PHASE }
| "RZ"                  { RZGATE }
| "RY"                  { RYGATE }
| "RX"                  { RXGATE }
| "U"                   { UNITARY }
| "CNOT"whitespace      { CTRLNOT }
| "CH"whitespace        { CTRLH }
| "CS"whitespace        { CTRLS }
| "CCX"whitespace       { TOFFOLI }
| "SWAP"whitespace      { SWAP }
| "RZZ"                 { SYMMRZZ }
| "RYY"                 { SYMMRYY }
| "RXX"                 { SYMMRXX }

// String definitions
| variable      { let str = LexBuffer<_>.LexemeString lexbuf in VARIABLE(str) }
